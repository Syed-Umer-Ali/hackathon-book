---
sidebar_position: 1
title: Vision-Language-Action Overview
---

# Module 4: Vision-Language-Action (VLA) - Overview

<h2>Focus</h2>

The convergence of LLMs and Robotics.

<h2>Key Topics</h2>

<ul>
    <li>Voice-to-Action: Using OpenAI Whisper for voice commands.</li>
    <li>Cognitive Planning: Using LLMs to translate natural language ("Clean the room") into a sequence of ROS 2 actions.</li>
    <li>Capstone Project: The Autonomous Humanoid. A final project where a simulated robot receives a voice command, plans a path, navigates obstacles, identifies an object using computer vision, and manipulates it.</li>
</ul>